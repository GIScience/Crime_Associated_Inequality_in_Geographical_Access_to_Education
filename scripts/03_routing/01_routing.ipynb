{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import json\n",
    "import uuid\n",
    "import geopandas as gpd\n",
    "from geopandas import sjoin_nearest\n",
    "import requests\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, shape , Polygon, LineString ,MultiPolygon\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "import ORS      # import from Ors module folder\n",
    "from ORS.client import RoutingClient\n",
    "from ORS.route import Route\n",
    "from matplotlib.lines import Line2D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data and output folder paths\n",
    "data_folder_path = os.path.join('..', '..', 'data', '01_input_data')\n",
    "\n",
    "routing_output_folder_path = os.path.join('..', '..', 'data', '02_intermediate_output', 'routing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the young population grids already created in  QGIS\n",
    "young_data = gpd.read_file(os.path.join(data_folder_path, 'young_population_grid.gpkg'))\n",
    "\n",
    "# load the schools data\n",
    "schools_osm = gpd.read_file(os.path.join(data_folder_path, 'schools_osm.gpkg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess data for routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Young mean</th>\n",
       "      <th>Id</th>\n",
       "      <th>sum</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_school</th>\n",
       "      <th>osm_id</th>\n",
       "      <th>amenity</th>\n",
       "      <th>distance_to_school</th>\n",
       "      <th>geometry_school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004387</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>POINT (-43.79522 -22.90463)</td>\n",
       "      <td>701</td>\n",
       "      <td>823942258</td>\n",
       "      <td>school</td>\n",
       "      <td>7382.502411</td>\n",
       "      <td>POINT (-43.72337 -22.90078)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004881</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008887</td>\n",
       "      <td>POINT (-43.79527 -22.90586)</td>\n",
       "      <td>701</td>\n",
       "      <td>823942258</td>\n",
       "      <td>school</td>\n",
       "      <td>7396.860207</td>\n",
       "      <td>POINT (-43.72337 -22.90078)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006552</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>POINT (-43.79516 -22.90699)</td>\n",
       "      <td>701</td>\n",
       "      <td>823942258</td>\n",
       "      <td>school</td>\n",
       "      <td>7395.964279</td>\n",
       "      <td>POINT (-43.72337 -22.90078)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005898</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>POINT (-43.79352 -22.90309)</td>\n",
       "      <td>701</td>\n",
       "      <td>823942258</td>\n",
       "      <td>school</td>\n",
       "      <td>7200.536924</td>\n",
       "      <td>POINT (-43.72337 -22.90078)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005199</td>\n",
       "      <td>4</td>\n",
       "      <td>0.028538</td>\n",
       "      <td>POINT (-43.79408 -22.90414)</td>\n",
       "      <td>701</td>\n",
       "      <td>823942258</td>\n",
       "      <td>school</td>\n",
       "      <td>7262.701492</td>\n",
       "      <td>POINT (-43.72337 -22.90078)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Young mean  Id       sum                     geometry  index_school  \\\n",
       "0    0.004387   0  0.001152  POINT (-43.79522 -22.90463)           701   \n",
       "1    0.004881   1  0.008887  POINT (-43.79527 -22.90586)           701   \n",
       "2    0.006552   2  0.000570  POINT (-43.79516 -22.90699)           701   \n",
       "3    0.005898   3  0.001244  POINT (-43.79352 -22.90309)           701   \n",
       "4    0.005199   4  0.028538  POINT (-43.79408 -22.90414)           701   \n",
       "\n",
       "      osm_id amenity  distance_to_school              geometry_school  \n",
       "0  823942258  school         7382.502411  POINT (-43.72337 -22.90078)  \n",
       "1  823942258  school         7396.860207  POINT (-43.72337 -22.90078)  \n",
       "2  823942258  school         7395.964279  POINT (-43.72337 -22.90078)  \n",
       "3  823942258  school         7200.536924  POINT (-43.72337 -22.90078)  \n",
       "4  823942258  school         7262.701492  POINT (-43.72337 -22.90078)  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter only school amenities from OSM data\n",
    "schools_osm = schools_osm[schools_osm['amenity'] == 'school']\n",
    "\n",
    "# Calculate centroids for young data\n",
    "young_data['geometry'] = young_data['geometry'].centroid\n",
    "\n",
    "# Perform a spatial join to find the nearest school for each young data point\n",
    "joined_young_schools = gpd.sjoin_nearest(young_data, schools_osm, distance_col=\"distance_to_school\",\n",
    "                                         lsuffix=\"young\", rsuffix=\"school\")\n",
    "\n",
    "# Change CRS to EPSG 4326 for the joined data\n",
    "joined_young_schools = joined_young_schools.to_crs(epsg=4326)\n",
    "\n",
    "# Change CRS to EPSG 4326 for the schools' geometry data\n",
    "schools_osm_geometry = schools_osm[['osm_id', 'geometry']].copy()\n",
    "schools_osm_geometry = schools_osm_geometry.to_crs(epsg=4326)\n",
    "\n",
    "route_df = joined_young_schools.merge(schools_osm_geometry, on='osm_id', how='left', suffixes=('', '_school'))\n",
    "\n",
    "route_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining avopid polygon  routes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read AVOID POLYGON\n",
    "geojson_file_path = os.path.join(data_folder_path, 'dispute_area.geojson')\n",
    "\n",
    "with open(geojson_file_path, 'r') as f:\n",
    "    geojson_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates from the GeoJSON file\n",
    "coordinates = []\n",
    "\n",
    "for feature in geojson_data['features']:\n",
    "    if feature['geometry']['type'] == 'MultiPolygon':\n",
    "        for polygon in feature['geometry']['coordinates']:\n",
    "            coordinates.append(polygon)\n",
    "    elif feature['geometry']['type'] == 'Polygon':\n",
    "        coordinates.append(feature['geometry']['coordinates'])\n",
    "\n",
    "# Create the avoid_polygons variable\n",
    "avoid_polygons = {\n",
    "    \"coordinates\": coordinates,\n",
    "    \"type\": \"MultiPolygon\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add intersecting column of avoid polygon for  short trips\n",
    "polygons = []\n",
    "for feature in geojson_data['features']:\n",
    "    geometry = feature['geometry']\n",
    "    if geometry['type'] == 'MultiPolygon':\n",
    "        for polygon in geometry['coordinates']:\n",
    "            polygons.append(shape({'type': 'Polygon', 'coordinates': polygon}))\n",
    "    elif geometry['type'] == 'Polygon':\n",
    "        polygons.append(shape(geometry))\n",
    "\n",
    "avoid_multipolygon = MultiPolygon(polygons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORS route functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " check if local ORS build running here >>> http://localhost:8081/ors/v2/health "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ors_url=\" http://localhost:8081/ors\" \n",
    "profile = \"foot-walking\" \n",
    "ors_client = RoutingClient(base_url=ors_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_default_ors_request(coord1, coord2, csv_factor, avoid_polygons=None):\n",
    "    \"\"\"\n",
    "    Create a default OpenRouteService request.\n",
    "    \"\"\"  \n",
    "\n",
    "    preferences = \"shortest\"      # can be preferences = \"fastest\" \n",
    "    coord1 = (coord1.x, coord1.y)    # Convert coordinates to tuples\n",
    "    coord2 = (coord2.x, coord2.y)\n",
    "   \n",
    "    extra = ['csv'] \n",
    "    col = 'crime_index' # csv column defined in the csv file \n",
    "\n",
    "    default_ors_request = {\n",
    "        \"instructions\": False,\n",
    "        \"preference\": preferences,\n",
    "        \"elevation\": False,\n",
    "        \"continue_straight\": True,\n",
    "        \"extra_info\": extra,\n",
    "        \"options\": {\n",
    "            \"avoid_features\": [\"ferries\"],\n",
    "            \"profile_params\": {\n",
    "                \"weightings\": {\n",
    "                    \"csv_factor\": csv_factor, # csv factor range from 0 to 1 (o.0/1.0)\n",
    "                    \"csv_column\": col\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"coordinates\": [coord1, coord2],\n",
    "    }\n",
    "    if avoid_polygons is not None:\n",
    "        default_ors_request[\"options\"][\"avoid_polygons\"] = avoid_polygons # add avoid polygons to the request if provided\n",
    "    \n",
    "    return default_ors_request\n",
    "\n",
    "\n",
    "def fetch_route_data(coord1, coord2, csv_factor, avoid_polygons=None):\n",
    "    \"\"\"\n",
    "    Helper function to make a request to the API and retrieve the route data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare the API request parameters\n",
    "        default_ors_request = make_default_ors_request(coord1, coord2, csv_factor, avoid_polygons)\n",
    "        \n",
    "        # Make the API call and get the response\n",
    "        normal_response = ors_client.request(params=default_ors_request, profile=profile, format=\"geojson\")\n",
    "        \n",
    "        # Extract route data from the response\n",
    "        normal_route = normal_response.routes[0]\n",
    "        df = normal_route.as_dataframe()\n",
    "        \n",
    "        return df, normal_route\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ors(gdf, csv_factor, avoid_polygons=None):\n",
    "    \"\"\"\n",
    "    Calculate route information from each origin to the nearest school.\n",
    "    \"\"\"\n",
    "    # Ensure 'geometry' and 'geometry_school' columns are points\n",
    "    gdf['geometry'] = gdf['geometry'].apply(lambda x: x if isinstance(x, tuple) else x)\n",
    "    gdf['geometry_school'] = gdf['geometry_school'].apply(lambda x: x if isinstance(x, tuple) else x)\n",
    "    \n",
    "    route_geometries = []\n",
    "    route_distances = []\n",
    "    route_durations = []\n",
    "    route_csv_means = []\n",
    "    route_csv_maxes = []\n",
    "    route_ids = []  # List to store respective IDs\n",
    "    \n",
    "    for index, row in tqdm(gdf.iterrows(), total=gdf.shape[0]):\n",
    "        # Fetch route data\n",
    "        df, normal_route = fetch_route_data(row['geometry'], row['geometry_school'], csv_factor, avoid_polygons)\n",
    "        \n",
    "        if df is not None and normal_route is not None:\n",
    "            csv_mean = df['csv'].mean()  # Get the mean value of the CSV column\n",
    "            csv_max = df['csv'].max()    # Get the maximum value of the CSV column\n",
    "            dis = normal_route.distance  # Get the distance of the route in meters\n",
    "            dur = normal_route.duration  # Get the duration of the route in seconds\n",
    "            geom = normal_route.geometry # Get the geometry of the route\n",
    "            \n",
    "            # Append to lists\n",
    "            route_geometries.append(geom)\n",
    "            route_distances.append(dis)\n",
    "            route_durations.append(dur)\n",
    "            route_csv_means.append(csv_mean)\n",
    "            route_csv_maxes.append(csv_max)\n",
    "            route_ids.append(row['Id'])  # Store respective ID\n",
    "        else:\n",
    "            # Append none values\n",
    "            route_geometries.append(None)\n",
    "            route_distances.append(None)\n",
    "            route_durations.append(None)\n",
    "            route_csv_means.append(None)\n",
    "            route_csv_maxes.append(None)\n",
    "            route_ids.append(row['Id'])  # Store respective ID\n",
    "\n",
    "    # Create a new GeoDataFrame\n",
    "    new_gdf = gpd.GeoDataFrame(gdf)  # Copy the original GeoDataFrame\n",
    "    new_gdf['route_geometry'] = route_geometries  # Add route geometries\n",
    "    new_gdf['route_distance'] = [d / 1000 if d is not None else None for d in route_distances]  # Convert route distance from meters to kilometers\n",
    "    new_gdf['route_duration'] = [d / 60 if d is not None else None for d in route_durations]  # Convert route duration from seconds to minutes\n",
    "    new_gdf['route_csv_mean'] = route_csv_means # Add route CSV means\n",
    "    new_gdf['route_csv_max'] = route_csv_maxes  # Add route CSV maximum values\n",
    "    new_gdf['Id'] = route_ids  # Add respective IDs\n",
    "    \n",
    "    return new_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_allroute(input_df, output_filename):\n",
    "    # Select necessary columns and rename geometry column\n",
    "    gdf = input_df[['route_geometry', 'Id', 'osm_id', 'route_distance', 'route_duration','route_csv_max', 'route_csv_mean']].copy()\n",
    "    gdf = gdf.rename(columns={'route_geometry': 'geometry'})\n",
    "    # Drop rows with missing geometry\n",
    "    gdf = gdf.dropna(subset=['geometry'])\n",
    "    #Create GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(gdf, geometry='geometry')\n",
    "    # Set CRS to EPSG:4326\n",
    "    gdf.crs = \"EPSG:4326\"\n",
    "    # Save to file\n",
    "    gdf.to_file(output_filename, driver='GPKG')\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run route request for short and safe route and save dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:14<00:00, 13.61it/s]\n"
     ]
    }
   ],
   "source": [
    "short_df = ors(route_df, csv_factor=0.0, avoid_polygons= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(routing_output_folder_path, 'Short_df_lines.gpkg')\n",
    "short_df_lines = save_allroute(short_df, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column with 0 or 1 if it intersects with avoid polygon\n",
    "short_df_lines['intersects_polygon'] = short_df_lines['geometry'].apply(lambda x: 0 if avoid_multipolygon.intersects(x) else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:24<00:00,  8.19it/s]\n"
     ]
    }
   ],
   "source": [
    "safe_df = ors(route_df, csv_factor=1.0, avoid_polygons=avoid_polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(routing_output_folder_path, 'safe_df_lines.gpkg')\n",
    "safe_df_lines = save_allroute(safe_df, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter ID if not starting & ending at same point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering safe routes:   0%|          | 0/132 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering safe routes: 100%|██████████| 132/132 [00:01<00:00, 97.46it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create copies of DataFrames for processing\n",
    "filtered_short_df = short_df_lines.copy()\n",
    "filtered_safe_df = safe_df_lines.copy()\n",
    "\n",
    "# Initialize columns for start and end matching indicators\n",
    "filtered_safe_df['start_match'] = ''\n",
    "filtered_safe_df['end_match'] = ''\n",
    "\n",
    "# Iterate over rows in filtered_short_df to filter safe routes\n",
    "for idx, row in tqdm(filtered_short_df.iterrows(), total=len(filtered_short_df), desc='Filtering safe routes'):\n",
    "    origin_id = row['Id']\n",
    "    \n",
    "    # Fetch geometries from filtered_safe_df and filtered_short_df\n",
    "    safe_geometry = filtered_safe_df.loc[filtered_safe_df['Id'] == origin_id, 'geometry'].iloc[0] if not filtered_safe_df.loc[filtered_safe_df['Id'] == origin_id].empty else None\n",
    "    short_geometry = filtered_short_df.loc[filtered_short_df['Id'] == origin_id, 'geometry'].iloc[0] if not filtered_short_df.loc[filtered_short_df['Id'] == origin_id].empty else None\n",
    "    \n",
    "    # Check if both geometries exist\n",
    "    if safe_geometry is not None and short_geometry is not None:\n",
    "        # Check if start coordinates match\n",
    "        if safe_geometry.coords[0] != short_geometry.coords[0]:\n",
    "            filtered_safe_df.loc[filtered_safe_df['Id'] == origin_id, 'start_match'] = 'Mismatch'\n",
    "        \n",
    "        # Check if end coordinates match\n",
    "        if safe_geometry.coords[-1] != short_geometry.coords[-1]:\n",
    "            filtered_safe_df.loc[filtered_safe_df['Id'] == origin_id, 'end_match'] = 'Mismatch'\n",
    "    else:\n",
    "        # Handle cases where one or both geometries are None\n",
    "        if safe_geometry is None:\n",
    "            filtered_safe_df.loc[filtered_safe_df['Id'] == origin_id, 'start_match'] = 'No Safe Geometry'\n",
    "            filtered_safe_df.loc[filtered_safe_df['Id'] == origin_id, 'end_match'] = 'No Safe Geometry'\n",
    "        if short_geometry is None:\n",
    "            filtered_safe_df.loc[filtered_safe_df['Id'] == origin_id, 'start_match'] = 'No Short Geometry'\n",
    "            filtered_safe_df.loc[filtered_safe_df['Id'] == origin_id, 'end_match'] = 'No Short Geometry'\n",
    "\n",
    "# Identify IDs to keep based on start or end matching criteria\n",
    "cleaned_safe_ids = filtered_safe_df[((filtered_safe_df['start_match'] != 'Mismatch') & (filtered_safe_df['end_match'] != 'Mismatch'))]['Id']\n",
    "cleaned_short_ids = filtered_short_df[filtered_short_df['Id'].isin(cleaned_safe_ids)]['Id']\n",
    "\n",
    "# Filter DataFrames based on identified IDs to keep\n",
    "filtered_safe_df = filtered_safe_df[filtered_safe_df['Id'].isin(cleaned_safe_ids)]\n",
    "filtered_short_df = filtered_short_df[filtered_short_df['Id'].isin(cleaned_short_ids)]\n",
    "\n",
    "filtered_merged_data = route_df[route_df['Id'].isin(cleaned_safe_ids)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get processed data for each rotues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates similarity ratios, filters inaccessible routes, categorizes route durations and distances, computes percentage increases, and calculates increases in crime mean and max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def share_ratio(geometry1, geometry2):\n",
    "    intersection = geometry1.intersection(geometry2)\n",
    "    if intersection.is_empty:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return (intersection.length / geometry1.length) * 100\n",
    "    \n",
    "\n",
    "def get_processed_data(csv, merged_data, short_df, avoid_polygons):\n",
    "    \n",
    "    safe_df = ors(merged_data, csv_factor=csv, avoid_polygons=avoid_polygons)    # Construct the ORS URL\n",
    "    \n",
    "    similarity_ratios = []\n",
    "    for idx, row in tqdm(short_df.iterrows(), total=len(short_df), desc='Calculating similarity ratios'):\n",
    "        origin_id = row['Id']\n",
    "        # Check if origin_id exists in safe_df\n",
    "        if origin_id in safe_df['Id'].values:\n",
    "            safe_geometry = safe_df.loc[safe_df['Id'] == origin_id, 'route_geometry'].iloc[0]\n",
    "            short_geometry = short_df.loc[short_df['Id'] == origin_id, 'geometry'].iloc[0]\n",
    "            if safe_geometry is not None and short_geometry is not None:\n",
    "                similarity_ratio = share_ratio(short_geometry, safe_geometry)\n",
    "            else:\n",
    "                similarity_ratio = float('nan')  # or 0.0\n",
    "        else:\n",
    "            similarity_ratio = float('nan')  # or 0.0\n",
    "            \n",
    "        similarity_ratios.append(similarity_ratio)\n",
    "\n",
    "    safe_df['similarity_ratio'] = similarity_ratios\n",
    "\n",
    "    # Merge data\n",
    "    merged_df = pd.merge(short_df[['Id',  'route_duration','route_distance', 'route_csv_max', 'route_csv_mean','intersects_polygon']], \n",
    "                         safe_df[['Id', 'route_duration','route_distance', 'route_csv_max', 'route_csv_mean','similarity_ratio','total_population']], \n",
    "                         on='Id', suffixes=('_short', '_safe'))\n",
    "    # Define bins and labels\n",
    "    bins = [0, 10, 20, 30, 40, 50, float('inf')]\n",
    "    bin_labels = ['0-10', '10-20', '20-30', '30-40', '40-50', '50+']\n",
    "    merged_df['duration_bins_short'] = pd.cut(merged_df['route_duration_short'], bins=bins, labels=bin_labels, right=False)\n",
    "    merged_df['duration_bins_safe'] = pd.cut(merged_df['route_duration_safe'], bins=bins, labels=bin_labels, right=False)\n",
    "    \n",
    "    bins = [0, 1, 2, 3, 4, 5, float('inf')]\n",
    "    bin_labels = ['0-1', '1-2', '2-3', '3-4', '4-5', '5+']\n",
    "    merged_df['distance_bins_safe'] = pd.cut(merged_df['route_distance_safe'], bins=bins, labels=bin_labels, right=False)\n",
    "    merged_df['distance_bins_short'] = pd.cut(merged_df['route_distance_short'], bins=bins, labels=bin_labels, right=False)\n",
    "\n",
    "\n",
    "    # Calculate percentage increase\n",
    "    merged_df['percentage_increase_dur'] = ((merged_df['route_duration_safe'] - merged_df['route_duration_short']) / merged_df['route_duration_short']) * 100\n",
    "    merged_df['percentage_increase_dis'] = ((merged_df['route_distance_safe'] - merged_df['route_distance_short']) / merged_df['route_distance_short']) * 100\n",
    "\n",
    "    merged_df[(merged_df['percentage_increase_dur'] < 400)]  #### filter ouliers\n",
    "\n",
    "    # Calculate increase ratio for max intersecting safety score\n",
    "    merged_df['increase_ratio_mean'] = ((merged_df['route_csv_mean_safe'] - merged_df['route_csv_mean_short']) / merged_df['route_csv_mean_short'] * 100) \n",
    "    merged_df['increase_ratio_max'] = ((merged_df['route_csv_max_safe'] - merged_df['route_csv_max_short']) / merged_df['route_csv_max_short']* 100)\n",
    "    # inf_rows = processed_data_10[processed_data_10[\"increase_ratio_mean\"] == float(\"inf\")] # max is also same rows\n",
    "\n",
    "    merged_df = merged_df.dropna(subset=['route_duration_short', 'route_duration_safe'])\n",
    "    \n",
    "    return merged_df, safe_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 , 1.0] #Run for differnt csv weights\n",
    "\n",
    "for csv in csv_values:\n",
    "    \n",
    "    processed_data, safe_df = get_processed_data(csv, filtered_merged_data, filtered_short_df, avoid_polygons)\n",
    "    \n",
    "    csv_filename = os.path.join(routing_output_folder_path, f'route_data_{csv}.csv') # save the processed data\n",
    "  \n",
    "    processed_data.to_csv(csv_filename, index=False)\n",
    "\n",
    "    # gpkg_filename = os.path.join(routing_output_folder_path, f'safe_df_csv_{csv}.gpkg') # save the safe data (optinal)\n",
    "\n",
    "    # save_allroute(safe_df, gpkg_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save route segements of every route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ors_df(gdf, csv_factor, avoid_polygons=None):\n",
    "    \"\"\"\n",
    "    Process origins and create a new GeoDataFrame with updated columns, then save route data as CSV files.\n",
    "    \"\"\"    \n",
    "    os.makedirs(routing_output_folder_path, exist_ok=True)\n",
    "    \n",
    "    gdf['geometry'] = gdf['geometry'].apply(lambda x: x if isinstance(x, tuple) else x)\n",
    "    gdf['geometry_school'] = gdf['geometry_school'].apply(lambda x: x if isinstance(x, tuple) else x)\n",
    "\n",
    "    # Iterate over each row in the GeoDataFrame\n",
    "    for _, row in gdf.iterrows():\n",
    "        coord1 = row['geometry']\n",
    "        coord2 = row['geometry_school']\n",
    "        row_id = row['Id']\n",
    "\n",
    "        # Fetch route data\n",
    "        df, _ = fetch_route_data(coord1, coord2, csv_factor, avoid_polygons)\n",
    "\n",
    "        if df is not None:\n",
    "            # Create a subdirectory named after the csv_factor inside the output folder\n",
    "            dir_name = os.path.join(routing_output_folder_path, f'csv_factor_{csv_factor}')\n",
    "            os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "            # Define the file name using the row ID\n",
    "            file_name = os.path.join(dir_name, f\"{row_id}.csv\")\n",
    "\n",
    "            # Save the DataFrame to a CSV file\n",
    "            df.to_csv(file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "ors_df(filtered_merged_data, csv_factor=0.0,avoid_polygons= None)  # save Shortest route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ors_df(filtered_merged_data, csv_factor=1.0,avoid_polygons=avoid_polygons) # save Safest route"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
